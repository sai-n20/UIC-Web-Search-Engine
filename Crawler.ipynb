{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "startURL = \"https://cs.uic.edu\"\n",
    "allowedDomain = \"uic.edu\"\n",
    "hrefRegExp = re.compile('^[http].*'+ allowedDomain+ '.*')\n",
    "httpSchemeRegExp = re.compile('^[https]*:\\/\\/')\n",
    "headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36'}\n",
    "\n",
    "blacklistExts = {\".xlsx\", \".aspx\", \".js\", \".docx\", \".pdf\", \".mp4\", \".tar\", \".ppt\", \".zip\", \".gz\", \".png\", \".xls\", \".svg\",\n",
    "                 \".tgz\", \".css\", \".gif\", \".avi\", \".pptx\", \".ico\", \".doc\", \".jpg\", \".jpeg\"}\n",
    "\n",
    "pageLimit = 4500\n",
    "pagesCrawled = 0\n",
    "\n",
    "crawledList = []\n",
    "\n",
    "crawlQueue = deque()\n",
    "crawlQueue.append(startURL)\n",
    "\n",
    "pageTitles = []\n",
    "webPageData = []\n",
    "\n",
    "webGraph = nx.DiGraph()\n",
    "\n",
    "def expandWeb(graph, link, currentPage):\n",
    "    if graph.has_edge(currentPage, link):\n",
    "        graph[currentPage][link]['weight'] += 1\n",
    "    else:\n",
    "        graph.add_edge(currentPage, link, weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error URL: publicaffairs@uic.edu\n",
      "Cause: Invalid URL 'publicaffairs@uic.edu': No schema supplied. Perhaps you meant http://publicaffairs@uic.edu?\n",
      "Error URL: http://https://today.uic.edu/coronavirus\n",
      "Cause: HTTPConnectionPool(host='https', port=80): Max retries exceeded with url: //today.uic.edu/coronavirus (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000015BCC09A220>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error URL: http://exedweb.cc.uic.edu/uiconline/uic_online.asp\n",
      "Cause: HTTPConnectionPool(host='exedweb.cc.uic.edu', port=80): Max retries exceeded with url: /uiconline/uic_online.asp (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000015BCB3B9CD0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error URL: http://https://comm.uic.edu/profiles/zizi-papacharissi\n",
      "Cause: HTTPConnectionPool(host='https', port=80): Max retries exceeded with url: //comm.uic.edu/profiles/zizi-papacharissi (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000015BCD48DA00>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error URL: https://cada.uic.edu/about/covid-19-updates\n",
      "Cause: HTTPSConnectionPool(host='cada.uic.edu', port=443): Read timed out. (read timeout=4)\n",
      "Error URL: https://ccspd.org.uic.edu\n",
      "Cause: HTTPSConnectionPool(host='ccspd.org.uic.edu', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000015BCBC80D30>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error URL: http://http://ahs.uic.edu\n",
      "Cause: HTTPConnectionPool(host='http', port=80): Max retries exceeded with url: //ahs.uic.edu (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000015BCDC0BAC0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error URL: https://today.uic.edu/chicagos-racial-wealth-gap-examined-in-new-uic-report\n",
      "Cause: HTTPSConnectionPool(host='today.uic.edu', port=443): Max retries exceeded with url: /chicagos-racial-wealth-gap-examined-in-new-uic-report (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000015BCC3066A0>, 'Connection to today.uic.edu timed out. (connect timeout=4)'))\n",
      "Error URL: http://fmweb.fm.uic.edu\n",
      "Cause: HTTPConnectionPool(host='fmweb.fm.uic.edu', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000015BCB34D790>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error URL: https://cada.uic.edu/news/design-with-company-guest-edits-mas-context-character\n",
      "Cause: HTTPSConnectionPool(host='cada.uic.edu', port=443): Read timed out. (read timeout=4)\n",
      "Error URL: https://cada.uic.edu/academics/student-report\n",
      "Cause: HTTPSConnectionPool(host='cada.uic.edu', port=443): Read timed out. (read timeout=4)\n",
      "Error URL: https://cada.uic.edu/admissions/virtualresourcelibrary\n",
      "Cause: HTTPSConnectionPool(host='cada.uic.edu', port=443): Read timed out. (read timeout=4)\n",
      "Error URL: https://cada.uic.edu/news-events/news\n",
      "Cause: HTTPSConnectionPool(host='cada.uic.edu', port=443): Read timed out. (read timeout=4)\n",
      "Error URL: https://cada.uic.edu/academics/advising\n",
      "Cause: HTTPSConnectionPool(host='cada.uic.edu', port=443): Read timed out. (read timeout=4)\n",
      "Error URL: https://cada.uic.edu/admissions/admitted-students-week\n",
      "Cause: HTTPSConnectionPool(host='cada.uic.edu', port=443): Read timed out. (read timeout=4)\n",
      "Error URL: https://locomotor.uic.edu\n",
      "Cause: HTTPSConnectionPool(host='locomotor.uic.edu', port=443): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000015BCDCA5520>, 'Connection to locomotor.uic.edu timed out. (connect timeout=4)'))\n",
      "Error URL: https://theatreandmusic.uic.edu/degree-auditions\n",
      "Cause: HTTPSConnectionPool(host='theatreandmusic.uic.edu', port=443): Read timed out. (read timeout=4)\n",
      "Error URL: https://ccspd.org.uic.edu\n",
      "Cause: HTTPSConnectionPool(host='ccspd.org.uic.edu', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000015BD0774580>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error URL: http://newsphoto.lib.uic.edu/v/the+future+of+the+city\n",
      "Cause: HTTPConnectionPool(host='newsphoto.lib.uic.edu', port=80): Max retries exceeded with url: /v/the+future+of+the+city (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x0000015BD0568160>, 'Connection to newsphoto.lib.uic.edu timed out. (connect timeout=4)'))\n",
      "Error URL: https://mapthecount.uic.edu\n",
      "Cause: HTTPSConnectionPool(host='mapthecount.uic.edu', port=443): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000015BCB9A7130>, 'Connection to mapthecount.uic.edu timed out. (connect timeout=4)'))\n",
      "Error URL: http://https://ask.library.uic.edu/widget_standalone.php\n",
      "Cause: HTTPConnectionPool(host='https', port=80): Max retries exceeded with url: //ask.library.uic.edu/widget_standalone.php (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000015BD2AE4790>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error URL: https://arch.uic.edu/school-architecture-fall-2020-faqs\n",
      "Cause: HTTPSConnectionPool(host='arch.uic.edu', port=443): Read timed out. (read timeout=4)\n",
      "Error URL: https://design.uic.edu/current-students\n",
      "Cause: HTTPSConnectionPool(host='design.uic.edu', port=443): Read timed out. (read timeout=4)\n",
      "Error URL: https://gallery400.uic.edu/interact/internships\n",
      "Cause: HTTPSConnectionPool(host='gallery400.uic.edu', port=443): Read timed out. (read timeout=4)\n",
      "Error URL: https://gallery400.uic.edu/blog\n",
      "Cause: HTTPSConnectionPool(host='gallery400.uic.edu', port=443): Read timed out. (read timeout=4)\n",
      "Error URL: https://tigger.uic.edu/depts/oar/grad/check_status_grad.html\n",
      "Cause: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory'))\n",
      "Error URL: http://ecc.engr.uic.edu\n",
      "Cause: HTTPConnectionPool(host='ecc.engr.uic.edu', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000015BD31405E0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error URL: http://https://ask.library.uic.edu/widget_standalone.php\n",
      "Cause: HTTPConnectionPool(host='https', port=80): Max retries exceeded with url: //ask.library.uic.edu/widget_standalone.php (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000015BCB90AF10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error URL: https://oia.uic.edu\n",
      "Cause: HTTPSConnectionPool(host='oia.uic.edu', port=443): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000015BD3E41E50>, 'Connection to oia.uic.edu timed out. (connect timeout=4)'))\n",
      "Error URL: http://uicems.uic.edu\n",
      "Cause: HTTPConnectionPool(host='uicems.uic.edu', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x0000015BCB695A00>, 'Connection to uicems.uic.edu timed out. (connect timeout=4)'))\n",
      "Wall time: 50min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "while crawlQueue:\n",
    "    try:\n",
    "        if pagesCrawled >= pageLimit:\n",
    "            break\n",
    "        currentURL = crawlQueue.popleft()\n",
    "        currentReq = requests.get(currentURL, verify=False, allow_redirects=False, timeout=4, headers=headers)\n",
    "        if(currentReq.status_code == 200):\n",
    "            dupeURLcheck = re.sub(httpSchemeRegExp, \"\", currentURL.replace(\"www.\", \"\"))\n",
    "            if dupeURLcheck not in crawledList:\n",
    "                pagesCrawled += 1\n",
    "                crawledList.append(dupeURLcheck)\n",
    "                soup = BeautifulSoup(currentReq.text, \"lxml\")\n",
    "\n",
    "                try:\n",
    "                    pageTitle = soup.title.text.replace('\\n', '')\n",
    "                    pageTitle = re.sub(\"\\s+\", \" \", pageTitle)\n",
    "                    pageTitles.append(pageTitle)\n",
    "                except Exception as error:\n",
    "                    pageTitle = \"Error in fetching page title\"\n",
    "                    pageTitles.append(pageTitle)\n",
    "\n",
    "                webPageData.append(pageTitle + \" \" + re.sub('\\s+', ' ', soup.get_text()))\n",
    "\n",
    "                pagesToExplore = soup.find_all(\"a\", href=hrefRegExp)\n",
    "                pagesToExplore = [i.get('href') for i in pagesToExplore]\n",
    "                pagesToExplore = set(pagesToExplore)\n",
    "                for page in pagesToExplore:\n",
    "                    pageLink = page.lower()\n",
    "                    if not any(extension in pageLink for extension in blacklistExts):\n",
    "                        pageLink = pageLink.split(\"#\")[0].split(\"?\", maxsplit = 1)[0].rstrip(\"/\").strip()\n",
    "                        dupeURLcheck = re.sub(httpSchemeRegExp, \"\", pageLink.replace(\"www.\", \"\"))\n",
    "                            \n",
    "                        expandWeb(webGraph, dupeURLcheck, re.sub(httpSchemeRegExp, \"\", currentURL.replace(\"www.\", \"\")))\n",
    "                        if len(crawlQueue) <= (pageLimit-pagesCrawled):\n",
    "                            if allowedDomain in dupeURLcheck and dupeURLcheck not in crawledList and pageLink not in crawlQueue:\n",
    "                                crawlQueue.append(pageLink)\n",
    "\n",
    "    except Exception as error:\n",
    "        print(\"Error URL:\", currentURL)\n",
    "        print(\"Cause:\", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pageRank = nx.pagerank(webGraph, weight='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pageList.txt', \"wb\") as out:\n",
    "    pickle.dump(crawledList, out)\n",
    "out.close()\n",
    "\n",
    "with open('pageTitles.txt', \"wb\") as out:\n",
    "    pickle.dump(pageTitles, out)\n",
    "out.close()\n",
    "\n",
    "with open('webData.txt', \"wb\") as out:\n",
    "    pickle.dump(webPageData, out)\n",
    "out.close()\n",
    "\n",
    "with open('page_rank.pkl', 'wb') as out:\n",
    "    pickle.dump(pageRank, out)\n",
    "out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}